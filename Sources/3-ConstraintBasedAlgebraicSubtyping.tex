\newcommand{\mlsub}{\textsc{MLsub}}
\newcommand{\simplesub}{\textsc{Simple-sub}}
\newcommand{\mlstruct}{\textsc{MLstruct}}
\newenvironment{example}{%
\begin{tcolorbox}[%
    colback=blue!5!white,% 
    colframe=blue!60!black,%
    title=\textsc{Example}%
]%
}{%
\end{tcolorbox}%
}

\chapter{Constraint-Based Algebraic Subtyping}
\label{algebraic-subtyping}

Part of the convenience of programming with dynamic typing is the absence of type annotations. 
This comfort comes at a price -- we cannot ensure any safety guarantees at compile-time. 
The aim of this thesis is to statically type languages with similar flexibility in mind. As such, we need to recover static types in the absence of annotations -- to have \emph{implicit typing} \cite{remy-record-inference}). This is the mission statement of \textbf{type inference} \cite{tapl}.

In this chapter, I explore the problem of type inference for languages with structural subtyping. In doing so, I follow Dolan's seminal thesis on \textbf{algebraic subtyping} -- a type inference technique in the presence of subtyping and (bounded) parametric polymorphism. Specifically, I contribute the following:
\begin{itemize}
    \item A \textbf{constraint-based type inference framework} -- \inference{} -- based on the current state-of-the-art in algebraic subtyping. The framework does not fix specific type or expression languages -- it sets out some requirements for them (the \textit{signature}) and operates on an intermediate \emph{constraint language}. The constraint-based description is simple and direct, though formal and close to the implementation. As such, it is a step towards understanding when we can apply algebraic subtyping in practice.
    \item An extension of algebraic subtyping that supplements the type language with applications of \textbf{type lattice homomorphisms}, described for the framework. Using this extension, I give a method to statically type extensible records using algebraic subtyping -- a novel alternative to row polymorphism. 
\end{itemize}

We begin with background on type inference, including our constraint-based setting and a review of the developments in algebraic subtyping (Section \ref{sec:ch3background}).The rest of the chapter's contents are the description of the framework. Firstly, in Section \ref{sec:signature} I give a description of the \textbf{signature} of the source language -- the requirements on the type language. Afterwards, in Section \ref{sec:constraints} I explain the \textbf{constraint solving} approach in \inference{}, and show the homomorphism extension in Section \ref{sec:morphisms}. Finally, I state and conjecture the correctness theorems of the framework in Section \ref{sec:correctness}. 

\begin{example}
    To ease understanding, the technical text of this chapter will be interleaved with boxes like this one, containing examples using Featherweight Lua (with some described extensions).
\end{example}

\section{Background}
\label{sec:ch3background}

Since this chapter concerns describing algebraic subtyping in the framework of constraint-based type inference, I explain these two concepts. We also set up the setting of the type inference problem we consider. 

\subsection{Type inference}
\emph{Type inference} (also called \emph{type reconstruction}), at its core, concerns determining the type $\tau$ of a given expression $e$ under an environment $\Gamma$, under some typing judgement $\Gamma \vdash e : \tau$.

\paragraph{Polymorphism \& type schemes} Type inference is straightforward in a \emph{simply-typed} setting. This is often unsatisfactory -- for instance, $\mathrm{id} =  \lambda x \ldotp x$ has type $\tau \to \tau$ for any type $\tau$.
This leads us to \textbf{parametric polymorphism}, where types contain type variables (denoted $\alpha, \beta, \gamma, \dots$), which can stand for any type. 
In this setting, expressions are not only given a type $\tau$, but a \textbf{type scheme} $\sch$ which can be \textbf{instantiated} to a type $\tau$ (written $\sch \models \tau$). A type scheme stands for any of these instantiations, and we define a judgement $\Gamma \vdash e : \sigma$ for ascribing a type scheme:
$$ \dfrac{\forall \tau \ldotp\; \sch \models \tau \implies \Gamma \vdash e : \tau}{\Gamma \vdash e : \sigma} $$
As expected, $\cdot \vdash \mathrm{id} : \forall \alpha \ldotp \alpha \to \alpha$.

The classical solution to type inference under parametric polymorphism is through the Hindley-Milner (HM) type system, which relies on unifications to compute most-general type substitutions \cite{essence-of-ml-type-inference, tapl}. It underlies type systems of languages in the ML family.

In this chapter, we will consider type inference in the presence of $F_\sub$-style \textbf{bounded} parametric polymorphism (in essence, \emph{bounded quantification} of \textcite{bounded-quantification}). Our type schemes $\sch$ have a form reminiscent of Java-style generics \cite{generic-java, simple-sub}:
$$ \sch ::= \forall \overline{\tau \sub \alpha \sub \tau} \ldotp \tau $$
where the body $\tau$ of $\sch$ must not contain unquantified type variables, and unspecified lower/upper bounds are presumed $\bot$/$\top$. 
Instantiation $\models$ derives from a type assignment $\psi ::= \cdot \mid \tau/\alpha$, which satisfies the bounds for each free type variable $\alpha$. Writing $[\psi]\tau$ for a substitution in $\tau$ under $\psi$, we have:
$$ \dfrac{\overline{[\psi]\tau_\alpha^+ \sub \substx{\psi} \alpha \sub [\psi]\tau_\alpha^-}}{\forall \overline{\tau_\alpha^+ \sub \alpha \sub \tau_\alpha^-} \ldotp \tau \models \substx{\psi}{\tau}} $$
In particular, if $\sigma \models \tau$, then $\tau$ has no free type variables.

\begin{example}
    We extend FL with bounded parametric polymorphism from here onwards. 

    Consider $e = \fllam x\, \flproj{x}{\mathrm{foo}}$. Then we have both 
    $$ \cdot \vdash e : \forall \alpha, (\beta \sub \flrec{\mathrm{foo} : \alpha}) \ldotp \beta \to \alpha  \quad \text{and} \quad \cdot \vdash e : \underbrace{\forall  \alpha \ldotp \flrec{\mathrm{foo} : \alpha} \to \alpha}_\sigma $$
    And we have that $\sigma \models \flrec{\mathrm{foo} : \sint} \to \sint$ at $\sint/\alpha$.
    
    The existence of many valid type schemes points us to type scheme simplification -- here, we obtain the second type scheme by \emph{inlining} the bound on $\beta$ in the first. This is an important topic in type inference with subtyping, and one we consider at the end of Section \ref{subsec:simplification}.
\end{example}

We shall allow bounds $\tau_\alpha^+$/$\tau_\alpha^-$ in type schemes to refer to other type variables, which naturally leads us to including recursive types in the type language.
Specifically, we will consider type systems with \textbf{equirecursive types}, meaning they are infinite terms in the type language -- as opposed to isorecursive types, where recursive types are given by finite types which are (un)folded explicitly \cite{tapl}. We will write $\rec \alpha \tau$ for a type  such that instances of $\alpha$ are equal to the entire type.
\begin{example}
    We further extend FL with equirecursive $\mu$ types. 
    The type $\tau = \rec \alpha \top \to \alpha$ corresponds to the infinite type $\top \to (\top \to (\top \to \cdots)))$. Given $\cdot : e : \tau$ and $\cdot : e' : \top$ we have $\cdot : e\,e' : \tau$. Hence, $\tau$ is the type of a function that takes an infinite number of arguments.
\end{example}

We define two more concepts useful for dealing with type schemes: \emph{subsumption} and \emph{principality} (minimality). We define that $\sigma'$ \textbf{subsumes} $\sigma$, written $\sigma \subsume \sigma'$, as follows:
$$ \sigma \subsume \sigma' \iff \forall \tau \ldotp (\sigma \models \tau \impliedby \sigma' \models \tau) $$
meaning that $\sigma'$ admits all the types that $\sigma$ does.
Based on subsumption, we define the \textbf{principal} type scheme $\sigma$ for an expression $e$ as the one that subsumes all its other type schemes $\sigma'$ (it is minimal\footnote{When we take the preorder $\subsume$ on all type schemes $\sigma$ for which $\Gamma \vdash e : \sigma$.}), i.e.\@:
$$ \sigma\text{ principal} \iff \forall \sigma' \ldotp \left( \Gamma \vdash e : \sigma' \implies \sigma \subsume \sigma' \right) $$
Subsumption can be seen as a generalisation of subtyping to type schemes.
\begin{example}
Consider the following type schemes:
$$    \sigma^+ = \forall \alpha, \beta \ldotp \alpha \to \beta
\quad \sigma' = \forall \beta \ldotp \flrec{} \to \beta 
\quad \sigma'' = \forall \alpha \ldotp \alpha \to \flrec{} 
\quad \sigma^- = \flrec{} \to \flrec{} $$
Then $\sigma^+ \subsume \sigma' \subsume \sigma^-$ and $\sigma^+ \subsume \sigma'' \subsume \sigma^-$, but neither $\sigma' \subsume \sigma''$ nor $\sigma'' \subsume \sigma'$. 
\end{example}

\paragraph{Constraint-based approach} While type schemes let us describe the \emph{result} of type inference, we can use \textbf{constraints} to describe type inference \emph{problems}. To this end, we follow the approach outlined in \citetitle{essence-of-ml-type-inference} by \textcite{essence-of-ml-type-inference} (\textcite[Chapter~10]{adv-tapl}).

This chapter will focus on constraint solving in the presence of subtyping, so we give an adequately simple constraint language in Figure \ref{fig:constraints} with only one predicate -- subtyping $\tau \sub \tau$, where types $\tau$ may contain type variables. We also feature constraint conjunction $c \und c$ and allow introducing existential variables $\exists \alpha \ldotp c$. The constraint satisfaction judgement $\psi \vdash c$ (where $\psi$ binds all free type variables in $c$) defined in Figure \ref{fig:satisfaction} gives a semantics to this syntax, specifying what variable assignments $\psi$ satisfy a given constraint $c$. In constraint solving nomenclature, we are dealing with a cylindric constraint system \cite{constraint-based-hm}. 

\begin{figure}
    \centering
    \begin{align*}
        \graintro c 
        \tru
        & \text{(always-true)}
        \graitem
        \fals
        & \text{(always-false)}
        \graitem
        \tau \sub \tau 
        & \text{(subtyping)}
        \graitem
        c \und c
         & \text{(conjunction)}
        \graitem 
        \exists \alpha \ldotp c
        & \text{(existential)}
    \end{align*}
    \caption{Syntax of constraints $c$ used in this chapter.}
    \label{fig:constraints}
\end{figure}

\begin{figure}
    \centering
    $$
    \irule{CTrue}{}{\psi \vdash \tru}
    \quad
    \irule{CSub}{\substx \psi \tau \sub \substx \psi \tau'}{\psi \vdash \tau \sub \tau'}
    \quad
    \irule{CAnd}{\psi \vdash c \quad \psi \vdash c'}{\psi \vdash c \und c'}
    \quad 
    \irule{CExist}{\psi, \tau/\alpha \vdash c}{\psi \vdash \exists \alpha \ldotp c}
    $$
    \caption{Constraint satisfaction judgement $\psi \vdash c$, defined for a type variable assignment $\psi$ and constraint $c$. Note that $\psi \vdash \fals$ is false for any $\psi$ ($\fals$ signals failure of inference -- type errors), and $\psi \vdash \tru$ is true for any $\psi$.}
    \label{fig:satisfaction}
\end{figure}
 
To construct a type inference problem as a constraint $c$ from an expression $e$ in the source language and its expected type $\tau$, we use \textbf{constraint generation} $\denot{e : \tau} = c$. Crucially, we require it agrees with typing:\footnote{Some standard presentations instead modify the type-scheme judgement to involve constraints, i.e.\@ $c; \Gamma \vdash e : \sigma$ \cite{essence-of-ml-type-inference}. For simplicity of the presentation, we take specific instantiations $\substx \psi \tau$, closer to e.g.\@ \cite[Section 3.4]{constraint-based-freeze-ml}.}
$$ \psi \vdash \denot{e : \tau} \iff \substx{\psi}\Gamma \vdash e : \substx \psi \tau $$

Since in type inference we do not know the specific type $\tau$, we can introduce it as a free variable in a constraint $\denot{e : \alpha}$. Analogously, if an expression contains `type holes' (like unannotated types of function parameters) these can be filled with type variables and constrained appropriately \cite{tapl}.

\begin{example}
    Consider $e = \fllam{x: \beta} \flproj{x}{\mathrm{quack}}\,\{\}$. Then we might have:
    $$ \denot{e : \alpha} = \exists \gamma \ldotp \beta \sub \flrec{\mathrm{quack}: \gamma} \und \exists \delta \ldotp \gamma \sub \flrec{} \to \delta \und \delta \sub \alpha $$
    where complete constraint generation for FL is defined in Appendix \ref{extra:fl-constraints}. Note that subtyping constraints and introduced type variables roughly follow the program dataflow \cite{mlsub}.

    We will later see this constraint system can be rewritten to $\exists \gamma \ldotp \flrec{\mathrm{quack} : \flrec{} \to \gamma} \to \gamma \sub \alpha$, and hence $\cdot \vdash e : \forall \gamma \ldotp \flrec{\mathrm{quack} : \flrec{} \to \gamma} \to \gamma$.
\end{example}\todo[color=green]{extra}

Lastly, we shall have \emph{constraint equivalence} $\cstreq$ such that:
$$ c \cstreq c' \iff  \forall \psi \ldotp \; (\psi \vdash c \iff \psi \vdash c') $$

The description of \inference{} is given so that we could instantiate an existing constraint-based type inference framework like $\mathrm{HM}(X)$ of \textcite{constraint-based-hm}. Thus, we do not consider let-polymorphism (like \textcite{dolan-thesis} and \textcite{simple-sub} do algebraic subtyping) which $\mathrm{HM}(X)$ could yield \enquote{for free}.

% It is worth noting here that this treatment of type inference is a bit different to the common Hindley-Milner type inference. There, we reason about unification and most general substitutions, but are also limited to an equality (rather than subtyping) predicate in constraints. Dolan's \emph{algebraic subtyping} (which we expand on in the next section) also reasoned about \emph{biunification} \emph{bisubstitutions}, more recent work moved towards a constraint-based approach, and this is the one we shall follow.

\subsection{Algebraic subtyping}

Combining bounded parametric polymorphism with both principal type inference and decidability of type scheme subsumption proved to be a difficult problem, which led to a general distrust in implicit subtyping as part of language design \cite{mlstruct} -- so much so that research would avoid subtyping due to its problematic interaction with type inference (see e.g.\@ \cite[Section~3.5]{linear-haskell}). Seminal work in the area is by \textcite{pottier-thesis}, who set out a framework for type inference under subtyping, but did not reach a satisfactory solution. The problem was ultimately resolved by \textcite{dolan-thesis} in his thesis.

\subsubsection{Original work (Dolan)}
There are two (closely tied) core principles guiding Dolan's approach \cite[Section~1.3]{dolan-thesis}: \begin{description}
    \item[Extensibility] Dolan identified that a core problem in previous solutions was closed-world reasoning on the language of types \cite[Section~1.3.1]{dolan-thesis}. Thus, he requires \emph{extensibility}: that for considered type systems, extending their type language preserves typing of programs.
    \item[Algebra before syntax] Furthermore, Dolan found that the previous focus on syntactic approaches to defining the type language and subtyping over it neglected ensuring these are well-behaved \cite[Section~1.3.2]{dolan-thesis}. Thus, he argued for an algebraic approach to constructing the type language. Indeed, extensibility motivated many of these algebraic properties \cite[Section~2.1.5]{dolan-thesis}.
\end{description}
Using these principles and a careful formal treatment relying on abstract algebra, Dolan invented \mlsub{} -- a statically typed language with support structural subtyping, building on core ML, and boasting ML-style type inference with bounded parametric polymorphism and decidable type scheme subsumption.

Two assumptions underlie \mlsub{} which enable its properties: subtyping forming a \textbf{distributive lattice}, and the \textbf{polarity restriction} of the type language. While Dolan uses an HM-like presentation to type inference (with \emph{bi}unification and \emph{bi}subsitution), I illustrate these assumptions in a constraint-based setting. \begin{description}
    \item[Distributive lattice] While constructing a lattice of types for conveniently well-behaved subtyping relations was standard, Dolan found it crucial for the lattice to also be \emph{distributive} \cite[Section~3.2]{dolan-thesis}.\footnote{Looking ahead, \ref{fig:boolean-laws} lists the laws of a distributive lattice ($\mathsf L \cup \mathsf B$).} While his main motivation is to ensure subsumption is decidable, this is a useful assumption in general.
    \item[Polarity restriction] Furthermore, Dolan uses a \emph{polar types} construction due to \textcite{pottier-thesis} \cite[Section~5.1]{dolan-thesis}. It means that we split the type language into positive $\tau^+$ and negative $\tau^-$ types -- corresponding to \emph{outputs} (for which we wish to give lower-bound on the type) and \emph{inputs} (dually: upper-bound). We then restrict joins and meets so that $\tau^+ ::= \cdots \mid \tau^+ \join \tau^+$ and $\tau^- ::= \cdots \mid \tau^- \meet \tau^-$,
    and also restrict type constructors so that polarities agree with their variance.\footnote{Covariance preserves polarity, but contravariance flips it: for functions, $\tau^+ ::= \cdots \mid \tau^- \to \tau^+$ and $\tau^- ::= \cdots \mid \tau^+ \to \tau^-$}
    
    The polarity restriction ensures subtyping constraints have form $\tau^+ \sub \tau^-$ (cf.\@ output-to-input dataflow \cite[Section~1.1]{dolan-thesis}). Hence, we can \emph{split} meets and joins via lattice laws \cite{simple-sub}: 
    \begin{align*}
        \tau' \join \tau'' \sub \tau \iff \tau' \sub \tau \text{ and } \tau'' \sub \tau \qquad
        \tau \sub \tau' \join \tau'' \iff \tau \sub \tau' \text{ and } \tau \sub \tau''
    \end{align*}

    A practical consequence of the polarity restriction is that we cannot type functions as $\alpha \to \alpha \meet \beta$ -- i.e.\@ ones \enquote{strengthening} the type of a value. The assumption was thus too restrictive for my approach to typing extensible records, and I chose to look for follow-up work. 
\end{description}

% \color{red}
% \subsubsection{Dolan's original work}

% The key aspects of Dolan's approach were to restrict the subtyping order to form a \textbf{distributive lattice} algebra and to impose the \textbf{polarity restriction} on types. Using these, \textcite{mlsub} gave a language design -- \mlsub{} -- with all the desired properties.

% \paragraph{Distributive lattice} Like Dolan, we also consider a distributive lattice of types (with some extensions). This means that our type language contains meets $\meet$ (least upper bounds) and joins $\join$ (greatest lower bounds):
% $$ \tau ::= \cdots \mid \tau \meet \tau \mid \tau \join \tau $$
% where we consider types under an equivalence relation given by algebraic laws of the distributive lattice. 

\begin{example}
    In the distributive lattice of FL types (see Appendix \ref{extra:fl-constraints}), we compute:
    \begin{align*}
        (\top \to \bot) \meet (\alpha \to \beta) &= \top \to \bot \\ 
        \flext{\mathrm{quack} : \top, \mathrm{walk} : \flrec{}}{\flabsent} \meet \flext{\mathrm{quack} : \top \to \top}{\flftop} &= \flext{\mathrm{quack}: \top \to \top, \mathrm{walk}: \flrec{}}{\flabsent} \\ 
        \flrec{\mathrm{foo}: \flrec{}} \join (\top \to \top) &= \top
    \end{align*}
\end{example}\todo[color=green]{extra}

% \paragraph{Polarity restriction} The polarity restriction (used by both \textcite{dolan-thesis} and \textcite{pottier-thesis}) splits types $\tau$ into positive types $\tau^+$ and negative types $\tau^-$, so that we only consider subtyping constraints of form $\tau^+ \sub \tau^-$. Intuitively, positive types are used for \emph{outputs} (thus, we use them as a lower bound, e.g.\@ a function's result), while negative types are used for \emph{inputs} (upper bounds, e.g.\@ function's argument).

% Crucially, \textcite{mlsub} not only adapt \mlsub{}'s type constructors to respect these polarities (in a manner matching their covariance/contravariance; e.g.\@ $\tau^+ ::= \cdots \mid \tau^- \to \tau^+$) -- this way, we only ever have subtyping constraints with matched polarities, i.e.\@ $\tau^+ \sub \tau^-$. Furthermore, they only permit joins in positive types, and meets in negative types:
% $$ \tau^+ ::= \cdots \mid \tau^+ \join \tau^+ \quad \tau^- ::= \cdots \mid \tau^- \meet \tau^- $$
% Together with the properties of the lattice algebra, this allows us to cleanly decompose and solve constraints $\tau^+ \sub \tau^-$ via the following pair of properties:
% \begin{align*}
% \tau' \join \tau'' \sub \tau \;&\iff \tau' \sub \tau \und \tau'' \sub \tau \\
% \tau \sub \tau' \meet \tau'' \;&\iff \tau \sub \tau' \und \tau \sub \tau'' 
% \end{align*}
% This property of lattices remains crucial in approaches that follow algebraic subtyping.

% However, the restriction of where meets and joins can occur in types -- and thus constraint solving -- means the language and its type system has to be carefully designed and certain types might not be expressible. 
% Notionally, to type-check updating the field of a record, we will need a primitive of a form that further constrains the type to a subtype with the field updated:
% $$ \forall \alpha, \beta \ldotp \alpha \to \alpha \land \flrec{\mathrm{foo}: \beta}  $$
% Such a type breaks the polarity restriction, since a negative type (with a $\meet$) occurs in a positive position (since the inferred type of an expression is a lower bound).
% Note this is not the type we actually use for typing extensible records, as there are problems with it -- we expand on this in Section \ref{sec:morphisms}.

% \paragraph{Formal treatment} Dolan's techniques revolved around the use of abstract algebra to prove the correctness of his techniques. For type inference itself, he parted with Pottier's constraint-oriented methods, and instead used biunification and bisubstitutions -- generalisation of standard notions in Hindley-Milner type inference to a setting with subtyping \cite{tapl, dolan-thesis}. 

\subsubsection{Later work (Parreaux, Chau)}

% \subsubsection{Later work}
% The name \textbf{algebraic subtyping} refers to these restrictions and techniques that Dolan invented, but this report also uses the name for closely related methods which followed, particularly due to \textcite{simple-sub} (\simplesub{}) and \textcite{mlstruct} (\mlstruct{}). These methods are connected, particularly by assumptions about the subtyping order forming a well-behaved algebra of types. We now explain the significance of their work as expanding on Dolan.

% \paragraph{\simplesub{}} 
% Dolan's approach, although formally solid, leads to a complex implementation. This is shown by \textcite{simple-sub}, when they find demonstrable bugs in Dolan's reference implementation, and introduce a comparatively simpler approach operating on a \emph{constraint graph}. 

While Dolan's work is foundational to this line of work, the approach in \inference{} is more closely descended from follow-up work: \simplesub{} of \textcite{simple-sub}, and \mlstruct{} of \textcite{mlstruct}. I highlight the following developments and their relation to my work: \begin{description}
    \item[Constraint graphs] \textcite{simple-sub} found that the \emph{biunification} approach Dolan uses can be difficult to implement and extend. He proposes an alternative approach in \simplesub{} that relies on explicitly introducing subtyping constraints and imperatively updating a \emph{constraint graph}. I also do not use Dolan's biunification (due to the next point), but my method does not rely on mutation.\footnote{While it is arguably a stylistic choice, purity seems to make the implementation easier to reason about.}
    \item[Boolean algebra] In Parreaux's constraint graph setting, \textcite{mlstruct} propose \mlstruct{}, featuring \emph{complement (negation) types} and removal of the polarity restriction. They use \simplesub{}-like constraint solving by requiring complements (with meets and joins) to form a \emph{Boolean algebra}\footnote{A bounded, distributive and complemented lattice.}. My approach to constraint solving directly inherits from theirs. However, I attempt to clarify that negations are only added to the type language as a \emph{free extension} of the distributive lattice of type constructors, and explain why they are a safe addition (Section~\ref{subsec:oh-god-complements}).
    \item[Non-extensibility] For Dolan, extensibility also means that \enquote{useless} types like $(\alpha \to \beta) \join \flrec{\ell : \gamma}$ should not be \emph{equal} to $\top$ \cite[Section~1.4.1]{dolan-thesis} -- even though they can only be eliminated as such. \textcite{mlstruct} disagree with this consequence (but not others, e.g.\@ distributivity), arguing that provides better user experience and eases constraint solving. I also simplify such types, but do not share their scepticism of extensibility \cite{simple-sub}, agreeing with Dolan that it is an important principle. 
\end{description}

\section{Signature}
\label{sec:signature}

We consider the external side of the \inference{} framework -- the \emph{signature}, i.e.\@ the requirements it entails on the source language. 
All constructs described here are available as \textbf{data} upholding certain \textbf{laws} when we later describe constraints and how we solve them in Section~\ref{sec:constraints}. To this end, I mainly endeavour to generalise the properties that are necessary for the \mlstruct{} solver to work.

\subsection{Type constructors}

Firstly, following standard practice \cite{essence-of-ml-type-inference, constraint-based-freeze-ml}, we will abstract away \emph{type constructors} in the type language. We will denote them $\constr[\overline \tau]$, where $\overline \tau$ stand for the list of types that occur within.
\begin{example}
    In FL we have the function and record type constructors. Writing \enquote{$\cdot$} for \emph{type holes} in constructors:
    $$
       \constr ::= \top \mid \bot \mid {\cdot} \to {\cdot} \mid \flext{\ell : \dot \phi}{\dot \phi} \qquad \dot \phi ::= \flftop \mid \flfbot \mid \cdot \mid \flabsent
    $$
    Writing $\constr[\overline \tau]$, we plug in $\overline \tau$ into each \enquote{$\cdot$} in $\constr$ in order. This establishes that type constructors $\constr$ non-opaquely contain subterms $\tau$. Here are example types $\constr[\overline \tau]$:
    $$
        (\cdot \to \cdot)[\top, \bot] = \top \to \bot \qquad \flext{\mathrm{foo}: \cdot, \mathrm{bar} : \flabsent}{\flftop}[\top \to \top] = \flext{\mathrm{foo}: \top \to \top, \mathrm{bar} : \flabsent}{\flftop}
    $$
\end{example}

We will require that type constructors $\constr[\overline \tau]$ form a distributive lattice $(\top, \bot, \cjoin, \cmeet)$, where $\top$ and $\bot$ are nullary type constructors and $\cjoin$ and $\cmeet$ are closed binary operators on type constructors. Furthermore, we require a \textbf{decomposition} operator $\constr[\overline \tau] \cdecomp \constr[\overline \tau] = c$, which decomposes a subtyping constraint between two type constructors into an equivalent one:
$$ (\constr'\left[\overline {\tau'}\right] \sub \constr''\left[\overline {\tau''}\right]) \cstreq (\constr\left[\overline {\tau'}\right] \cdecomp \constr'\left[\overline {\tau''}\right]) $$
where the resulting constraints contain structurally smaller type constructors.\footnote{We do not formalise this property, but it would be necessary to do so to prove the constraint solving process terminates.} Decomposition is where type errors may be raised in the system, e.g.\@ in the case $\top \cdecomp \bot = \fals$. Together with the type constructor lattice and constraint decomposition we will be able to effectively massage constraints involving type constructors. 
\begin{example}
    The type constructor lattice given by $\cmeet$ and $\cjoin$ agrees with $\meet$ and $\join$ on types, e.g.:
    \begin{align*}
       (\top \to \top) \meet (\bot \to \bot) 
       &\typeq (\cdot \to \cdot)[\top, \top] \cmeet (\cdot \to \cdot)[\bot, \bot] = (\cdot \to \cdot)[\top \cjoin \bot, \top \cmeet \bot] \\
       &= (\cdot \to \cdot)[\top, \bot] \typeq \top \to \bot 
    \end{align*}
    Constraints on function type constructors decompose as such:
    $$ (\tau \to \pi) \cdecomp (\tau' \to \pi') = \tau' \sub \tau \und \pi \sub \pi' $$
\end{example}

\begin{figure}
    \centering
    \begin{align*}
    \graintro \tau 
             \alpha & \text{(variable)}
    \graitem \constr[\overline \tau] & \text{(constructor)}
    \graitem \tau \join \tau & \text{(join)}
    \graitem \tau \meet \tau & \text{(meet)}
    \graitem \lnot \tau & \text{(complement)}
    \end{align*}
    \caption{Syntax of types $\tau$ in \inference{}.}
    \label{fig:signature-types}
\end{figure}

\begin{figure}
    \centering
    % $$ \mathbb B = (\tau, \sub, \top, \bot, \join, \meet) $$ 
    $$ \boxed{\tau \typeq \tau} $$
    $$ \renewcommand\arraystretch{1.1} \begin{array}{cr}
    \tau \join (\tau' \join \tau'') \typeq (\tau \join \tau') \join \tau'' \quad 
    & \text{($\mathsf L$: associativity \mbox{$\join$})}
    \\
    \tau \meet (\tau' \meet \tau'') \typeq (\tau \meet \tau') \meet \tau''
    \tau \join \tau' \typeq \tau' \join \tau  \quad 
    & \text{($\mathsf L$: associativity \mbox{$\meet$})} 
    \\
    \quad
    \tau \meet \tau' \typeq \tau' \meet \tau 
    & \text{($\mathsf L$: commutativity)}
    \\
    \tau \join (\tau \meet \tau') = \tau
    \quad 
    \tau \meet (\tau \join \tau') = \tau
    & \text{($\mathsf L$: absorption)}
    \\ 
    \tau \join \bot \typeq \tau
    \quad 
    \tau \meet \top \typeq \tau 
    & \text{($\mathsf B$: bounds)} 
    \\
    \tau \meet (\tau' \join \tau'') \typeq (\tau \meet \tau') \join (\tau \meet \tau'')
    & \text{($\mathsf D$: distributivity)}
    \\
    \tau \join \comp \tau = \top 
    \quad
    \tau \meet \comp \tau = \bot
    & \text{($\mathsf C$ complements)} 
    \\ 
    \constr_1\left[\overline {\tau'}\right] \join \constr_2\left[\overline {\tau''}\right] \typeq \constr_1\left[\overline {\tau'}\right] \cjoin \constr_2\left[\overline {\tau''}\right]
    & \text{(type constructor $\cjoin$/$\join$)}
    \\
    \constr_1\left[\overline {\tau'}\right] \meet \constr_2\left[\overline {\tau''}\right] \typeq \constr_1\left[\overline {\tau'}\right] \cmeet \constr_2\left[\overline {\tau''}\right]
    & \text{(type constructor $\cmeet$/$\meet$)}
    \\[0.5em] 
    \dfrac{\tau \typeq \tau'}{E[\tau] \typeq E[\tau']} 
    & \text{(congruence)}
    \end{array} $$
    $$ \equivctx ::= \ctxhole \mid \constr[\overline \tau, \ctxhole, \overline \tau] \mid \equivctx \join \tau \mid \tau \join \equivctx \mid \equivctx \meet \tau \mid \tau \meet \equivctx \mid \comp \equivctx $$
    \caption{Laws of the Boolean algebra of types and the lattice of type constructors, forming the equivalence $\tau \typeq \tau$. Equivalence contexts $\equivctx$ are used to specify the congruence rule. We have laws of a lattice ($\mathsf L$) that is bounded ($\mathsf B$), distributive ($\mathsf D$), and complemented ($\mathsf C$) -- altogether, a Boolean algebra.}
    \label{fig:boolean-laws}
\end{figure}

\subsection{Type language}

With the necessary structure of type constructors, we describe the syntax of types itself (Figure \ref{fig:signature-types}). Following \textcite{mlstruct}, we define it so that it forms the free Boolean algebra over type constructors and variables\footnote{Like \textcite{dolan-thesis}, our variables are \emph{opaque} in the lattice -- we do not make a closed-world assumption about their possible values.}. This algebra satisfies Boolean algebra laws and the laws of the type constructor lattice (Figure \ref{fig:boolean-laws}) under type equivalence $\tau \equiv \tau$.\footnote{Following this, the algebra of types is free extension of the algebra of type constructors with variables and complements.} As a coherence condition, subtyping $\sub$ must agree with the type algebra and the typing judgement:
$$ \begin{array}{c}
   \tau \sub \pi \iff \tau \typeq \tau \meet \pi \iff \pi \typeq \tau \join \pi \\[5pt]
   \dfrac{\Gamma \vdash e : \tau \quad \tau \sub \tau'}{\Gamma \vdash e : \tau'}
\end{array} $$

\subsection{Inclusion of complement types} 
\label{subsec:oh-god-complements}
Complement (or negation) types are a somewhat controversial addition in a type system. However, following \textcite{mlstruct}, our complement types have algebraic foundation, as opposed to a set-theoretic one. The two have different interpretations of subtyping:\footnote{The algebraic interpretation follows by: $\pi \sub \comp \tau \implies \pi \meet \tau \sub \tau \meet \comp \tau \implies \pi \meet \tau \sub \bot$, and $\pi \meet \tau \sub \bot \implies (\pi \meet \tau) \join \comp \tau \sub \comp \tau \implies (\pi \join \comp \tau) \meet (\pi \join \comp \tau) \sub \comp \tau \implies (\pi \join \comp \tau) \meet \top \sub \comp \tau \implies \pi \join \comp \tau \sub \comp \tau \implies \pi \sub \comp \tau$.}
\begin{align*}
    \pi \sub \dot \comp \tau \;&\iff \text{not } \pi \sub \tau & \text{(set-theoretic)} \\
    \pi \sub \comp \tau \;&\iff \pi \meet \tau \sub \bot & \text{(algebraic)} 
\end{align*}
Set-theoretic-like complement types notoriously make constraint solving harder, smuggling negations into the underlying logic of constraint satisfaction. On the other hand, our algebraic complement types provide a weaker condition, but will be of great help to constraint solving -- as we explore in Section \ref{fig:constraints}.

\begin{example}
    Take $\pi = \flext{\mathrm{foo}: \flabsent }{\flftop}$ and $\tau = \flext{\mathrm{foo}: \top}{\flftop}$. The two interpretations of $\pi \sub \comp \tau$ disagree: \begin{description}
        \item[Set-theoretic] It is not the case that $\pi \sub \tau$, thus we have $\pi \sub \dot \comp \tau$. $\checkmark$
        \item[Algebraic] We have $\pi \meet \tau = \flext{\mathrm{foo} : \flfbot }{\flftop} \not\sub \bot$, so we do not have $\pi \sub \comp \tau$. $\lightning$
    \end{description}
    Note that $\comp$ admits fewer subtypes than $\dot \comp$, since for any sets $A$ and $B$: 
    $$A \cap B = \varnothing \implies \lnot(A \subseteq B) \qquad\text{thus}\qquad \tau \sub \comp \pi \implies \tau \sub \dot\comp \pi $$ 
    % Intuitively, algebraically we require an empty (bottom) intersection between the types, not non-subset.
\end{example}

\subsection{Summary} To summarise the requirements of \inference{}'s signature: \begin{itemize}
    \item Type constructors must form a distributive lattice.
    \item We use a type language that forms a Boolean algebra.
    \item We must have an implicit subtyping rule in the type system.
\end{itemize} 
To determine these, I was inspired by the requirements of techniques of \textcite{mlsub} and \textcite{mlstruct}.
Later, we see that both Fabric (Chapter \ref{fabric}) and Star (Chapter \ref{star}) successfully implement the signature of \inference{}, showing it is reasonable in practice.

\section{Constraint solving}
\label{sec:constraints}

We now describe the \mlstruct{}-inspired constraint solving process used in \inference{} using the already described setting of the constraint language and signature. 

I largely follow the tradition of the framework by \textcite{pottier-framework} and the Boolean algebraic techniques of \textcite{mlstruct} in \mlstruct{}. The key difference to prior art is the use term rewriting of constraints, leading to a simpler presentation. Furthermore, in Section \ref{sec:morphisms} I give the main contribution of the framework: extension of the type language and constraint solving with homomorphism applications. Giving this extension is made much easier by a constraint-based presentation.

The section is structured as follows: \begin{description}
    \item[\ref{subsec:rewriting} Massaging] We first show that all subtyping constraints $\tau \sub \tau$ can be reduced to a conjunction of \emph{variable-bound} constraints (of syntax $\tau \sub \alpha \,\mid\, \alpha \sub \tau$ -- as in bounded parametric type schemes).
    \item[\ref{subsec:normalisation} Plumbing] Then, we show how we manipulate and combine these variable-bound constraints into a list-of-bounds normal form. We then perform the \emph{closure} computation.
    \item[\ref{subsec:simplification} Solutions] Lastly, we briefly consider how we can extract a type scheme from a normalised generated constraint, and how these can be simplified.
\end{description} 
Altogether, I reproduce the constraint solving of \textcite{mlstruct} in \mlstruct{} in a constraint-based style that is simpler and easier to extend. 

Constraint solving is given in terms of a small-step term rewriting relation $\step$. The solving process is given by its reflexive-transitive closure, $\step^*$ (\ref{fig:solver}).
To show constraint solving always yields correct result, we rely on a theorem that $\step^*$ preserves constraint satisfaction (with simple proofs for individual steps $\step$):\todo[color=green]{extra}
\begin{theorem}[Semantic preservation]
    If $c \step^* c'$, then $c \cstreq c'$.
\end{theorem}
We shall now consider various properties of constraint solving steps, giving proofs by construction -- these directly lead to a practical implementation.

\begin{figure}
    \centering
    \input{Sources/3-Figures/Solver}
    \caption{Definition of constraint solving steps $\step$. Congruence for $\step$ is given by constraint solving contexts $\solvectx$.}
    \label{fig:solver}
\end{figure}

\newcommand{\typcnf}{\tau_\text{cnf}}
\newcommand{\typcnfcls}{\tau_\text{cnf-clause}}
\newcommand{\typclsvars}{\tau_\text{cnf-clause-vars}}
\newcommand{\typvar}{\tau_\text{var}}
\newcommand{\vbnd}{V}
\newcommand{\vbnds}{\vbnd_{\undsym}}

\subsection{Massaging}
\label{subsec:rewriting}
We define the syntax of a \emph{variable bound} $\vbnd$ and \emph{variable bounds} $\vbnds$ as:
\begin{align*}
    \graintro \vbnd \tau \sub \alpha \mid \alpha \sub \tau \\
    \graintro {\vbnds} \tru \mid V \mid \vbnds \und \vbnds
\end{align*}
We shall show by construction that:
\begin{theorem}[Subtyping constraints yield variable bounds]
    Given $c = (\tau \sub \pi)$, we have that:
    $$ c \step^* \fals \;\text{ or }\; \exists c' = \vbnds \ldotp c \step^* c' $$
\end{theorem}
Let us call type constructors and type variables \emph{atoms}.
The proof sketch is as follows:
\begin{enumerate}
    \item Show all subtyping constraints are equivalent to $\top \sub \typcnf$,\footnote{Notice that $\top \sub \tau \iff \top = \tau$.} 
    for a type $\typcnf$ in \emph{conjunctive normal form} (or a \emph{meet-of-joins-of-atoms}) -- as defined in Figure \ref{fig:type-cnf}.
    \item From there, we split the constraint into a conjunction of constraints of the form $\top \sub \typcnfcls$, where $\typcnfcls$ is a CNF clause (or a \emph{join-of-atoms}).
    \item At this point, we use \emph{swapping} to give variable bounds for each occurring variable, yielding $\vbnds$.
\end{enumerate}
The technique is essentially the same as \textcite{mlstruct}, but I give a presentation that is generalised (up to the signature) and more direct (constraint-based). Just as them, I call this process \emph{constraint massaging}. 
% We now give a sketch of the main aspects of the construction.

\begin{figure}
    \centering
    \begin{align*}
    \graintro{\typcnf} \top \mid \typcnfcls \meet \typcnf \\
    \graintro{\typcnfcls} \constr \left[ \overline{\typcnf} \right] \join { \comp \constr \left[ \overline{\typcnf} \right]} \join \typclsvars \\
    \graintro{\typclsvars} \bot \mid \typvar \join \typclsvars \\
    \graintro{\typvar} \alpha \mid \comp \alpha
    \end{align*}
    \caption{Grammar of the conjunctive normal forms (CNF) for types $\tau$ -- a \emph{meet-of-clauses} $\typcnf$, where clauses $\typcnfcls$ are \emph{joins-of-atoms}. Clauses only one type constructor $\constr$ at each polarity, but many variables. We additionally require that no $\typvar$ occurs twice in $\typclsvars$.}
    \label{fig:type-cnf}
\end{figure}

\begin{proof}
We shall write $\mathrm{cnf}(\tau)$ for the $\typcnf$ such that $\tau \equiv \typcnf$. CNF can be built compositionally, analogically to usual Boolean algebraic techniques.\footnote{There is an analogous \emph{disjunctive normal form} (DNF) in my implementation -- while not necessary, it can be more size-efficient.} To transform any $c = \tau \sub \pi$ into $\top \sub \typcnf$ we step like so:
$$ \tau \sub \pi \stackrel{\text{swap}}{\step} \top \sub \comp \tau \meet \pi \stackrel{\text{equiv.}}{\step} \top \sub \mathrm{cnf}(\comp \tau \meet \pi) $$
at which point we reach a $c' = \top \sub \typcnf$ equivalent to $c$. By simple induction we can see that we can split this into a conjunction of constraints $\top \sub \typcnfcls$, since:
$$ \top \sub \typcnfcls \meet \typcnf \;\stackrel{\text{split}}{\step}\; \top \sub \typcnfcls \und \top \sub \typcnf $$
It remains to show $\top \sub \typcnfcls \step^* \vbnds$. Let $\typcnf = \constr' \left[ \overline{\typcnf'} \right] \join { \comp \constr'' \left[ \overline{\typcnf''} \right]} \join \typclsvars$. By cases: 
\begin{itemize}
    \item If $\typclsvars = \bot$, then:
    $$ \top \sub \constr' \left[ \overline{\tau'_\text{cnf}} \right] \join \comp \constr'' \left[ \overline{\tau''_\text{cnf}} \right] \join \bot \stackrel{\text{equiv.}}{\step} \cdots \stackrel{\text{swap}}{\step} \cdots \stackrel{\text{decomp.}}{\step} \constr'' \left[ \overline{\tau''_\text{cnf}} \right] \cdecomp \constr' \left[ \overline{\tau'_\text{cnf}} \right] $$
    and we proceed recursively at the result of $\cdecomp$, assuming it is well-behaved so we eventually terminate. This is the case where we might reach a \enquote{type-error} constraint $\fals$.
    \item If $\typclsvars = \typvar \join \typclsvars'$, the constraint is satisfiable ($\typvar \mapsto \top$). We return a conjunction of \textbf{separate}\footnote{It is \emph{sufficient} to take one $\typvar$ -- but any choice would be nondeterministic, so to find a principal type scheme we get all of~them.} constraints for each $\typvar$. We have one of two cases: \begin{itemize}
        \item If $\typvar = \alpha$, then $\top \sub \alpha \join \tau \stackrel{\text{swap}}{\step} \comp \tau \sub \alpha$.
        \item If $\typvar = \comp \alpha$, then $\top \sub \comp \alpha \join \tau' \stackrel{\text{swap}}{\step} \alpha \sub \tau'$.
    \end{itemize}
\end{itemize}
\end{proof}

\begin{example}
Here is an example of constraint massaging. 
Starting from:
$$ c = (\alpha \meet \flrec{} \to \beta) \sub (\flrec{\mathrm{foo}: \gamma} \to \top) $$
we decompose:
$$ c \step c' = \underbrace{\flrec{\mathrm{foo}: \gamma} \sub \alpha \meet \flrec{}}_{c''} \und \beta \sub \top $$
We consider the first conjunct $c''$ (the latter is solved), and transform into $\top \sub \typcnf$:
$$ c'' \step^* c''_\text{cnf} = \top \sub \underbrace{\left( \alpha \join \comp \flrec{\mathrm{foo}: \gamma} \right)}_\text{(1)} \meet \underbrace{\left( \flrec{} \join \comp \flrec{\mathrm{foo}: \gamma} \right)}_\text{(2)} $$
Splitting into clauses (1) and (2):
$$ \begin{cases} 
    \top \sub \alpha \join \comp \flrec{\mathrm{foo}: \gamma} \step \flrec{\mathrm{foo}: \gamma} \sub \alpha
    \\
    \top \sub \flrec{} \join \comp \flrec{\mathrm{foo}: \gamma} \step \flrec{\mathrm{foo}: \gamma} \sub \flrec{} \step \flrec{\mathrm{foo}: \gamma} \cdecomp \flrec{} = \tru
\end{cases}$$
Thus:
$$ c \step^* (\flrec{\mathrm{foo}: \gamma} \sub \alpha \und \tru) \und \beta \sub \top $$
Note that while negations appeared in intermediate constraints, they are not in the output.
\end{example}

\subsection{Plumbing}
    \label{subsec:normalisation}
    
\newcommand{\sbnd}{W}

We shall now consider the normalisation of variable bounds and the transitive closure computation in the style of \textcite{pottier-framework}. The use of these techniques was first described for algebraic subtyping by \textcite{simple-sub} for \simplesub{} (and thus inherited by \mlstruct{}) -- I adapt them to the constraint-based presentation.

Lists-of-bounds $\sbnd$ have syntax:
$$ \sbnd ::= \tru \mid (\tau \sub \alpha \und \alpha \sub \tau) \und \sbnd $$
constrained such that no $\alpha$ occurs twice, and $\alpha$s are sorted under a fixed total ordering. We have only shown that for subtyping constraints reduce to (multiset-like) variable bounds $V^*$, but we can strengthen this:
\begin{lemma}[Normalisation of bounds]
For any $c = \vbnds$, there exist $c' = \sbnd$ such that $c \step^* c'$.
\end{lemma}
\begin{proof}
    Straightforward by $\undsym$ forming a commutative monoid and by the \emph{combining} step.
\end{proof}
To move towards general constraints, we also give a lemma that existentials can be lifted to the top-level:
\begin{lemma}[Top-level existentials]
    For any $c$, there exist $c'$ such that $c'$ has no existentials and $c \step^* \overline{\exists{\alpha \ldotp {}}} c'$.
\end{lemma}
\begin{proof}
    This is simplified by the constraint language only featuring conjunctions and existentials besides the subtyping predicate. Straightforward using the fact $\exists$ can always be \emph{factored out} from conjunctions.
\end{proof}
Finally, we give the normal form of constraints $\hat c$ -- a list-of-bounds with top-level existentials:
$$ \hat c ::= \mathbf F \mid \overline{\exists \alpha \ldotp {}} \sbnd $$
and we state that \textbf{constraints normalise}:
\begin{theorem}[Normalisation of constraints]
For any $c$, there exist $\hat c$ such that $c \step^* \hat c$.
\end{theorem}
\begin{proof}
    By factoring out existentials to the top-level, and normalising the variable bounds.
\end{proof}
Lastly, whenever we are in a list-of-bounds form, we can invoke transitivity. This yields an additional constraint $\tau^+_\alpha \sub \tau^-_\alpha$ for each $\tau^+_\alpha \sub \alpha \und \alpha \sub \tau^-_\alpha$ in the list. Invoking transitivity and normalising can only yield stronger bounds, i.e.\@ the process is monotone under the order $\preceq$ defined as:\footnote{Introducing another subsumption-like relation might be surprising, but $\preceq$ is more useful here as it is syntactic (checks bounds) rather than semantic (as $\subsume$, which checks instantiations). It is also a stronger condition: $\preceq$ implies $\subsume$.}
$$ \hat c' \preceq \hat c \iff \hat c' = \fals \text{ or } (\forall \alpha \ldotp \pi_\alpha^+ \sub \tau_\alpha^+ \text{ and } \tau_\alpha^- \sub \pi_\alpha^-) $$
where $\tau_\alpha$ and $\pi_\alpha$ are the bounds on a variable $\alpha$ in $\hat c'$ and $\hat c$, respectively.
While it is expected this process terminates \cite{pottier-framework, simple-sub, mlstruct} -- determining the constraint is satisfiable -- I conjecture it and only verify it in practice:
\begin{conjecture}
    For any normalised constraint $\hat c$, applying transitivity at each $\alpha$ and leads to some $\hat c'$ such that $\hat c' \preceq \hat c$. This process eventually reaches a fixed-point. We call this fixed-point the \emph{solved constraint}, and denote it by $\mathcal S(c)$ for any initial $c$.
\end{conjecture}

\begin{example}
    Denoting applications of transitivity by $\Rightarrow$, consider two examples:
    \begin{align*}
        & \flext{\mathrm{quack}: \beta}{\flabsent} \sub \alpha \und \alpha \sub \flext{\mathrm{quack}: \top \to \top }{\flftop} \\
        \Rightarrow\;& \flext{\mathrm{quack}: \beta}{\flabsent} \cdecomp \flext{\mathrm{quack}: \top \to \top }{\flftop} = \gamma \sub \top \to \top
    \end{align*}
    where we obtained a bound on the type $\beta$ of the field $\mathrm{quack}$.
    $$ \top \to \top \sub \gamma \und \gamma \sub \flrec{} \;\implies\; \top \to \top \cdecomp \flrec{} = \fals $$
    where we reached a contradiction on satisfying bounds on $\gamma$.
\end{example}

\subsection{Solutions}
\label{subsec:simplification}

We now consider the question of extracting the type scheme from a solved constraint. Given a generated constraint $\denot{e : \tau}$, if it is solved successfully we have:
$$ \mathcal S \left( \denot{e : \tau} \right) = \overline{\exists \alpha \ldotp {}} \sbnd $$
in which case we (abusing notation with $W$) return the type scheme
$$ \sigma =  \forall W \ldotp \tau $$
It is important to simplify type schemes -- however, I do not propose novel ways to do this, and entirely refer to \textcite{simple-sub} and \textcite{mlstruct}. In practice, I have found that to ensure efficient termination I had to simplify the CNF (or DNF) forms. Inlining bounds (particularly done by \textcite{dolan-thesis}) and removing redundant type variables mainly serves to improve readability.

\begin{example}
    Given:
    $$ e =  $$
    we have:
    $$ \mathcal S(\denot{e : \tau}) = $$
    thus, $\Gamma \vdash e : \sigma$ at:
    $$ \sigma = \forall \ldotp  $$
    which can be equivalently (i.e.\@ $\sigma \subsume \sigma' \subsume \sigma$) simplified to $\sigma'$:
    $$ \sigma' = \forall \ldotp $$
\end{example}\todo[color=blue]{ex}

\section{Breaking records: Homomorphism extension}
\label{sec:morphisms}

The crucial issue identified early on by \textcite{operations-on-records} with typing extensible records using subtyping is the \emph{update problem}. We exemplify it on an FL program using record extension:
$$ e = \fllam x \fllam y \flext{\ell = y}{x} $$
which would naively be given the (non-principal) type scheme
$$ \cdot \vdash e : \forall \alpha \ldotp \flext{\ell : \flabsent}{\flftop} \to \alpha \to \flext{\ell : \alpha}{\flftop} $$
causing \emph{loss of information} about the non-$\ell$ fields of $x$. There is no obvious way in which just subtype and parametric polymorphism can capture that information -- hence, the standard solution to the problem is row polymorphism \cite{remy-records}, as row type variables can stand for other fields. 

We might prefer to avoid adding rows to the system -- avoiding the inherent complexity -- and to stick to just bounded parametric polymorphism. One approach is to update a specific field in the record type underlying a type variable \cite{operations-on-records} via a \enquote{type-function} $\mathrm{update}_\ell(\tau, \phi) = \tau$, like:
$$ \qquad \cdot \vdash e : \forall \alpha, \rho \sub \flext{\ell : \flabsent}{\flftop} \ldotp \rho \to \alpha \to \mathrm{update}_\ell(\rho, \alpha) \qquad \boxed{?!} $$
Indeed, it would be convenient to have \emph{metafunctions on types} to specify such type schemes.

I propose to follow the algebraic approach and exploit homomorphisms in the type algebra -- such well-behaved (meta)functions -- for this purpose. Thanks to homomorphism laws, we are able to successfully solve constraints involving homomorphism applications. Hence, they uncover a new direction in the design of type systems applying algebraic subtyping.

\begin{example}
    For typing extensible records, we shall develop a homomorphism $\mathrm{forget}_\ell$, which given a record type sends a field $\ell$ to $\flftop$.
    By sending the field $\ell$ to $\flftop$, we can intersect the result with a singleton record of $\ell$ to set it to a wanted field type ($\forall \phi \ldotp \flftop \meet \phi = \phi$). 
    For example:
    \setlength{\tabcolsep}{0pt}
    $$\begin{array}{rll}
        &\hspace{-0.9em}\tau &\;\hspace{-0.9em}= \flext{\mathrm{foo}: \flabsent}{\flabsent} \\
        \mathrm{forget}_\mathrm{foo}( &\hspace{-0.9em}\tau ) &\;\hspace{-0.9em}= \flext{\mathrm{foo}: \flftop}{\flabsent} \\
        \mathrm{forget}_\mathrm{foo}( &\hspace{-0.9em}\tau ) \meet \flext{\mathrm{foo}: \alpha}{\flftop} &\;\hspace{-0.9em}= \flext{\mathrm{foo}: \alpha}{\flabsent}
    \end{array}$$
    This shows how we will replace an absent field in a record with one present with $\alpha$.

    $\mathrm{forget}_\ell$ is reminiscent of the retraction operator on record types of \textcite{operations-on-records}.
\end{example}

\begin{figure}
    \centering
    $$\boxed{\tau \typeq \tau}$$
    \vspace{-2em}
    \begin{align*}
        \morph(\tau \meet \pi) &\typeq \morph(\tau) \meet \morph(\pi) \\
        \morph(\tau \join \pi) &\typeq \morph(\tau) \join \morph(\pi) \\
        \morph(\top) &\typeq \top \\
        \morph(\bot) &\typeq \bot
    \end{align*}
    \vspace{-1em}
    $$ \equivctx ::= \cdots \mid \morph(\equivctx) $$
    \caption{Homomorphism laws in the Boolean algebra of types, which extend the definition of equivalence $\tau \typeq \tau$. Note that $\morph(\comp \tau) \typeq \comp \morph(\tau)$ follows from these laws (by a routine check of complement axioms).}
    \label{fig:morphism-laws}
\end{figure}

\subsection{Signature}

We begin developing the idea formally by extending the syntax of types with \textbf{homomorphism applications} for some homomorphisms $\morph$ specific to a language, and including a homomorphism $\morph = \mathrm{id}$:
$$ \tau ::= \cdots \mid \morph(\tau) $$
requiring that equivalence of types respects the homomorphism laws (Figure \ref{fig:morphism-laws}) and that $\mathrm{id}(\tau) \typeq \tau$. 

In order to solve constraints in the presence of homomorphism applications, we require they have an \emph{adjoint-like}\footnote{Or, perhaps better said, Galois connection-like -- though adjoint is a convenient name.} structure given by left- and right-adjoint homomorphisms $\ladj \morph$ and $\radj \morph$ for all $\morph$. In practice, not all homomorphisms have an adjoint structure (which is why we call this data adjoint-like), thus we also allow \emph{remainder} constraint functions $\ladjrest \morph(\tau) = c$ and $\radjrest \morph(\tau) = c$, so that we have constraint equivalences:
\begin{align*}
(\morph(\tau) \sub \pi) \cstreq \left(\tau \sub \radj \morph(\pi) \und \radjrest \morph(\pi) \right) \\
(\tau \sub \morph(\pi)) \cstreq \left(\ladj \morph(\tau) \sub \pi \und \ladjrest \morph(\tau) \right)
\end{align*}
The use of $\ladjrest \morph$ and $\radjrest \morph$ makes it clear why we call these remainders: in the degenerate case that they introduce no further constraint ($\ladjrest \morph = \radjrest \morph = \tru$), $\ladjrest \morph$ and $\radjrest \morph$ are precisely left and right Galois connections to $\morph$.

\begin{example}
    In order to give adjoint-like structure $\mathrm{forget}_\ell$, we need a \enquote{dual} for it. We call this morphism $\mathrm{free}_\ell$, and define it so that it sends a field $\ell$ to $\flfbot$. Then we have the following adjoints and remainders:
    $$\begin{array}{c|cccc}
    \morph & \ladj \morph & \ladjrest \morph(\tau) & \radj \morph & \radjrest \morph(\tau) \\ \hline 
    \mathrm{forget}_\ell & \mathrm{free}_\ell & \tru & \mathrm{id} & \flext{\ell : \flftop}{\flfbot} \sub \tau \\
    \mathrm{free}_\ell & \mathrm{id} & \tau \sub \flext{\ell : \flfbot}{\flftop} & \mathrm{forget}_\ell & \tru \\ 
    \mathrm{id} & \mathrm{id} & \tru & \mathrm{id} & \tru 
    \end{array}$$
    $\mathrm{free}_\ell$ and $\mathrm{forget}_\ell$ form an \enquote{adjoint pair} (inspiring the naming, cf.\@ free-forgetful adjunction).
\end{example}

\subsection{Constraint solving}

We now extend the constraint solving process of Section \ref{sec:constraints} with support for homomorphism applications. This is relatively straightforward: we only need to amend the construction of variable bounds from subtyping constraints. Thus, we firstly amend the syntax of $\typvar$ (in $\typcnf$):
$$ \typvar ::= \morph(\alpha) \mid \comp  \morph(\alpha) $$
which generalises $\typvar$ (at $\morph = \mathrm{id}$).
Crucially, we can still construct the CNF thanks to the fact that $\morph$ are homomorphisms: we can we just \emph{push down} all applications.

For constructing variable bounds, only the final cases are affected -- we need to show $\top \sub \typvar \join \tau$ gives a variable bound. We sketch how to do this by exploiting the adjoint-like structure (via appropriate $\step$ rules):
\begin{itemize}
    \item If $\typvar = \morph(\alpha)$, then $\top \sub \morph(\alpha) \join \tau \stackrel{\text{swap}}{\step} \comp \tau \sub \morph(\alpha) \stackrel{\text{left-adj}}{\step} \ladj \morph(\tau) \sub \alpha \und \ladjrest \morph(\tau) $.
    \item If $\typvar = \morph(\comp \alpha)$, then $\top \sub \comp \morph(\alpha) \join \tau \stackrel{\text{swap}}{\step} \morph(\alpha) \sub \tau \stackrel{\text{right-adj}}{\step} \alpha \sub \radj \morph(\tau) \und \radjrest \morph(\tau)$.
\end{itemize}
where we proceed recursively on any remainder constraints. 
Note that constraints $\top \sub \typvar \join \tau$ remain always satisfiable, since we can always set $\typvar$ to $\top$ (since $\morph(\bot) \equiv \bot$, $\morph(\top) \equiv \top$).

\subsection{Typing extensible records}
Now that we have describe the use of type homomorphisms in constraint solving, we present the promised concrete application -- typing extensible records, presented for Featherweight Lua. To this end, we define the homomorphisms $\mathrm{forget}_\ell$ and $\mathrm{free}_\ell$ (introduced in examples):
$$ 
\dfrac
  {\tau = \flext{\ell' : \phi_{\ell'},  \overline{\ell : \phi_\ell}}{\phi}}
  {\mathrm{forget}_\ell(\tau) = \flext{\ell' : \flftop,  \overline{\ell : \phi_\ell}}{\phi}}
\qquad 
\dfrac
  {\tau = \flext{\ell' : \phi_{\ell'},  \overline{\ell : \phi_\ell}}{\phi}}
  {\mathrm{free}_\ell(\tau) = \flext{\ell' : \flfbot,  \overline{\ell : \phi_\ell}}{\phi}}
$$
The key property we make use of is that we can give a rule equivalent to the \emph{rule scheme} \textsc{FL-Typ-Ext} -- for which there is no clear way to generate constraints (while avoiding the update problem \cite{operations-on-records}). We instead use:
$$ 
\irule{FL-Typ-HExt}{\Gamma \vdash e : \tau \meet \flext{\ell : \flabsent}{\flftop} \quad \Gamma \vdash e' : \tau'}{\Gamma \vdash \flext{\ell = e'}{e} : \mathrm{forget}_\ell(\tau) \meet \flext{\ell : \tau'}{\flftop}}
$$
\textsc{FL-Typ-HExt} makes it straightforward to generate the necessary constraints (see Appendix \ref{extra:fl-constraints} for details).
% (sketch of the proofs of homomorphisms laws and equivalence of \textsc{FL-Typ-Ext} and \textsc{FL-Typ-HExt})
\todo[color=green]{extra}
Thus, I have solved the record update problem under algebraic subtyping without row polymorphism.

\section{Correctness}
\label{sec:correctness}

I state correctness theorems for \inference{}, particularly for \emph{solved constraints} $\mathcal S(c)$. We begin with soundness:
\begin{theorem}[Soundness]
    For all $\psi$ and $c$, $\psi \vdash \mathcal S(c)$ if and only if $\psi \vdash c$.
\end{theorem}
\begin{proof}
    Follows directly by semantic preservation of $c$, since $c \leadsto^* \mathcal S(c)$ by construction.
\end{proof}

However, I do not provide proofs for the following -- and only provide evidence based on the prototype implementation (Chapter \ref{fabric}), arguing that \inference{} generalises prior work where these hold. 

\begin{conjecture}[Termination]
    The constraint solving $\mathcal S(c)$ in Section \ref{sec:constraints} always terminates.
\end{conjecture}

\begin{conjecture}[Completeness]    
    For all $c$, $\mathcal S(c) \ne \fals$ if and only if $\exists \psi \ldotp \psi \vdash c$.
\end{conjecture}

\begin{conjecture}[Principality]
    Returned type schemes are minimal under both $\subsume$ and $\preceq$.
\end{conjecture}

Note that: \begin{itemize}
    \item Termination requires appropriate choices of $\cdecomp$, $\ladjrest \morph$/$\radjrest \morph$, and ensuring the fixed-point is found after a finite number of iterations.
    \item Completeness relies on the transitive closure finding all possible contradictions in the system -- which is a standard result in the work of \textcite{pottier-framework} and in constraint solving folklore.
    \item Principality for $\preceq$ seems straightforward (by construction of the closure), and leads to principality for $\subsume$ as $\preceq$ is a stronger condition.
\end{itemize}
We do not consider decidability of subsumption of type schemes (to the well-founded dismay of \textcite{dolan-thesis}). I rely on the claim of \textcite{mlstruct} that it is resolvable by solving an appropriate constraint.

\section{Conclusions}
\label{sec:conclusions}

I have described \inference{} -- a language-agnostic, constraint-based type inference framework based on algebraic subtyping, as introduced by \textcite{mlsub}.
It soundly infers bounded parametric type schemes in the presence of structural subtyping. 
I use elegant Boolean algebraic techniques -- as set out by \textcite{mlstruct} -- which I extend with the use of \emph{homomorphisms}. 
My description lends itself directly to an implementation -- this implementation is part of my deliverable, described in the following chapter.


